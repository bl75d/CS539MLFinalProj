{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jingfeng Xia\n",
    "# jxia@wpi.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn\n",
    "# !pip install yfinance\n",
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetStockData(ticker,prd,intvl):\n",
    "        rawdata = yf.download(  # or pdr.get_data_yahoo(...\n",
    "                # tickers list or string as well\n",
    "                tickers = ticker,\n",
    "\n",
    "                # use \"period\" instead of start/end\n",
    "                # valid periods: 1d,5d,1mo,3mo,6mo,1y,2y,5y,10y,ytd,max\n",
    "                # (optional, default is '1mo')\n",
    "                # period = \"ytd\",\n",
    "                period = prd,\n",
    "\n",
    "                # fetch data by interval (including intraday if period < 60 days)\n",
    "                # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "                # (optional, default is '1d')\n",
    "                interval = intvl,\n",
    "\n",
    "                # group by ticker (to access via data['SPY'])\n",
    "                # (optional, default is 'column')\n",
    "                group_by = 'ticker',\n",
    "\n",
    "                # adjust all OHLC automatically\n",
    "                # (optional, default is False)\n",
    "                # auto_adjust = True,\n",
    "\n",
    "                # download pre/post regular market hours data\n",
    "                # (optional, default is False)\n",
    "                prepost = True,\n",
    "\n",
    "                # use threads for mass downloading? (True/False/Integer)\n",
    "                # (optional, default is True)\n",
    "                threads = True,\n",
    "\n",
    "                # proxy URL scheme use use when downloading?\n",
    "                # (optional, default is None)\n",
    "                proxy = None\n",
    "            )\n",
    "        return rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata=GetStockData(\"AAPL\",\"max\",\"1d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename may change for difference cases\n",
    "rawdata.to_csv(\"AAPL_max_1d.csv\",index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file to save time\n",
    "rawdata = np.genfromtxt(\"AAPL_max_1d.csv\", delimiter=',', skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.ones(shape=(rawdata.shape[0],2))\n",
    "# data[:,0] = rawdata.iloc[:,3] # for pd.dataframe, if not using csv\n",
    "data[:,0] = rawdata[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(data,width):\n",
    "    for i in range(data.shape[0]-1):\n",
    "        if width*data[i,0]<data[i+1,0]: # buy\n",
    "            data[i,-1]=2\n",
    "        elif data[i,0]>width*data[i+1,0]: # sell\n",
    "            data[i,-1]=0\n",
    "        else:\n",
    "            pass\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldata = np.ones(data.shape)\n",
    "ldata = labeling(data[0:-1,:],1.006)\n",
    "# print(ldata[:50,:],ldata.shape)\n",
    "# type(ldata)\n",
    "# print(np.count_nonzero(ldata[:,1] == 0))\n",
    "# print(np.count_nonzero(ldata[:,1] == 1))\n",
    "# print(np.count_nonzero(ldata[:,1] == 2))\n",
    "\n",
    "# 1.007: 634 1059 824\n",
    "# 1.006: 699 928 890\n",
    "# 1.005: 774 784 959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocknlabel(data):\n",
    "    block = np.zeros((data.shape[0]-12*21,12,21))\n",
    "    label = np.ones((data.shape[0]-12*21,1))\n",
    "    for i in range(data.shape[0]-12*21): # reshape into a block.shape=(12,21) \n",
    "        block[i] = data[i:i+12*21,0].reshape(12,21)\n",
    "        label[i] = data[i+12*21,1]\n",
    "    return block,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = np.zeros((data.shape[0]-12*21,12,21))\n",
    "datalabel = np.ones((data.shape[0]-12*21,1))\n",
    "datablock,datalabel = blocknlabel(ldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6879, 12, 21, 1)\n",
      "(6879, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(datablock, datalabel, test_size=0.3, random_state=1206)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_train = np.squeeze(tf.one_hot(y_train,3))\n",
    "y_test = np.squeeze(tf.one_hot(y_test,3))\n",
    "# y_train = y_train.reshape(y_train,shape[0],3)\n",
    "# y_test = y_test.reshape(y_test,shape[0],3)\n",
    "X_train = X_train.reshape(X_train.shape[0],12,21,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],12,21,1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 12, 21, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               229504    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 230,531\n",
      "Trainable params: 230,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.2815 - accuracy: 0.3842\n",
      "Epoch 2/5\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0699 - accuracy: 0.3951\n",
      "Epoch 3/5\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0684 - accuracy: 0.3890\n",
      "Epoch 4/5\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0670 - accuracy: 0.3925\n",
      "Epoch 5/5\n",
      "69/69 [==============================] - 1s 9ms/step - loss: 1.0665 - accuracy: 0.3940\n",
      "215/215 [==============================] - 0s 1ms/step - loss: 1.0655 - accuracy: 0.3970\n",
      "train_loss: 1.065528392791748\n",
      "train_accuracy: 0.3970053791999817\n",
      "93/93 [==============================] - 0s 2ms/step - loss: 1.0693 - accuracy: 0.3910\n",
      "test_loss: 1.0693327188491821\n",
      "test_accuracy: 0.3909800052642822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64,3,strides=1,input_shape=(12,21,1),\\\n",
    "                 padding='same',activation='relu'))\n",
    "\n",
    "# keras.layers.convolutional.Conv2D(filters, kernel_size, strides=(1, 1), \\\n",
    "# padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, \\\n",
    "# use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', \\\n",
    "# kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, \\\n",
    "# kernel_constraint=None, bias_constraint=None)\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (3,3)))\n",
    "# model.add(Conv2D(64,(3,3),activation = 'relu',padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(3,activation = 'softmax'))\n",
    "print(model.summary())\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=sgd,metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size = 100,epochs = 5)\n",
    "score_tr = model.evaluate(X_train,y_train)\n",
    "print(\"train_loss: \"+str(score_tr[0]))\n",
    "print(\"train_accuracy: \"+str(score_tr[1]))\n",
    "score_te = model.evaluate(X_test,y_test)\n",
    "print(\"test_loss: \"+str(score_te[0]))\n",
    "print(\"test_accuracy: \"+str(score_te[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
